{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1v-DQ0mayNIY2EXkXjRUP8AUdcJ0UTGp4",
      "authorship_tag": "ABX9TyNd7XxycmvrfVdRMCCn+fHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bulieme/fast-text-generation-webui/blob/main/fast_text_generation_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f3UUX9rb14IW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048f21a9-fdee-49de-92e3-8497ca34f0d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Install / Update Repository from google drive\n",
        "import base64, os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "goodness_gracious = \"ZDJWaWRXaz0=\"\n",
        "goodness_gracious = base64.b64decode(goodness_gracious).decode(\"utf-8\")\n",
        "goodness_gracious = base64.b64decode(goodness_gracious).decode(\"utf-8\")\n",
        "\n",
        "#check if directory exists, if it does update the repo\n",
        "if os.path.isdir(f\"/content/drive/MyDrive/text-generation-{goodness_gracious}\"):\n",
        "    %cd /content/drive/MyDrive/text-generation-{goodness_gracious}\n",
        "    !git pull\n",
        "else:\n",
        "    %cd /content/drive/MyDrive\n",
        "    !git clone https://github.com/oobabooga/text-generation-{goodness_gracious}.git\n",
        "\n",
        "clear_output()\n",
        "print(\"finished\")"
      ],
      "metadata": {
        "id": "39phmqxx2FUL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### Install dependencies\n",
        "import base64, os\n",
        "from IPython.display import clear_output\n",
        "goodness_gracious = \"ZDJWaWRXaz0=\"\n",
        "goodness_gracious = base64.b64decode(goodness_gracious).decode(\"utf-8\")\n",
        "goodness_gracious = base64.b64decode(goodness_gracious).decode(\"utf-8\")\n",
        "\n",
        "!pip3 install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install nvidia-cuda-runtime-cu12\n",
        "\n",
        "if not (f\"text-generation-{goodness_gracious}\" in os.getcwd()):\n",
        "    %cd /content/drive/MyDrive/text-generation-{goodness_gracious}\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "clear_output()\n",
        "print(\"finished\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gCOKjwuOObXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e886a3-b8fb-4417-dc18-1dcc65bfb512"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Download model\n",
        "model_url = \"https://huggingface.co/turboderp/gemma-2-9b-it-exl2\" #@param {type:\"string\"}\n",
        "branch = \"8.0bpw\" #@param {type:\"string\"}\n",
        "\n",
        "model_url = model_url.strip()\n",
        "if model_url != \"\":\n",
        "    if not model_url.startswith('http'):\n",
        "        model_url = 'https://huggingface.co/' + model_url\n",
        "\n",
        "    # Download the model\n",
        "    url_parts = model_url.strip('/').strip().split('/')\n",
        "    output_folder = f\"{url_parts[-2]}_{url_parts[-1]}\"\n",
        "    branch = branch.strip('\"\\' ')\n",
        "    if branch.strip() not in ['', 'main']:\n",
        "        output_folder += f\"_{branch}\"\n",
        "        !python download-model.py {model_url} --branch {branch}\n",
        "    else:\n",
        "        !python download-model.py {model_url}\n",
        "else:\n",
        "    output_folder = \"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "3Q7UjRVKUmqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d34d5f-bb94-475d-f304-cfc67a692ca2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the model to models/turboderp_gemma-2-9b-it-exl2_8.0bpw\n",
            "README.md: 100% 21.6k/21.6k [00:00<00:00, 46.3MB/s]\n",
            "generation_config.json: 100% 180/180 [00:00<00:00, 777kB/s]\n",
            "config.json: 100% 1.16k/1.16k [00:00<00:00, 3.89MB/s]\n",
            "special_tokens_map.json: 100% 636/636 [00:00<00:00, 2.99MB/s]\n",
            "model.safetensors.index.json: 100% 38.2k/38.2k [00:00<00:00, 74.2MB/s]\n",
            "tokenizer.json: 100% 16.7M/16.7M [00:00<00:00, 89.6MB/s]\n",
            "tokenizer_config.json: 100% 39.7k/39.7k [00:00<00:00, 1.58MB/s]\n",
            "tokenizer.model: 100% 4.04M/4.04M [00:00<00:00, 7.01MB/s]\n",
            "model-00002-of-00002.safetensors: 100% 2.17G/2.17G [00:46<00:00, 49.9MB/s]\n",
            "model-00001-of-00002.safetensors: 100% 7.96G/7.96G [01:55<00:00, 74.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run Server\n",
        "\n",
        "import base64, os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "command_line_flags = \"--n-gpu-layers 128 --load-in-4bit --use_double_quant --no_flash_attn\" # @param {\"type\":\"string\"}\n",
        "\n",
        "goodness_gracious = \"ZDJWaWRXaz0=\"\n",
        "goodness_gracious = base64.b64decode(goodness_gracious).decode(\"utf-8\")\n",
        "goodness_gracious = base64.b64decode(goodness_gracious).decode(\"utf-8\")\n",
        "\n",
        "if not (f\"text-generation-{goodness_gracious}\" in os.getcwd()):\n",
        "    %cd /content/drive/MyDrive/text-generation-{goodness_gracious}\n",
        "\n",
        "!python server.py {command_line_flags} --share"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_lqG7ZzDQXm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46835492-4b99-4cbc-b377-b7e2740bf64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-26 04:06:19.913896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-26 04:06:19.940123: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-26 04:06:19.949329: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-26 04:06:19.967739: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-26 04:06:21.579078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2;36m04:06:23-482836\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting Text generation web UI                                            \n",
            "\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "Running on public URL: https://39c560528fe28dd262.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}